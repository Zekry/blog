<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Blog - Zekry</title><link href="https://zekry.github.io/blog/" rel="alternate"></link><link href="https://zekry.github.io/blog/feeds/zekry.atom.xml" rel="self"></link><id>https://zekry.github.io/blog/</id><updated>2019-07-05T09:30:00-04:00</updated><entry><title>Interpreting Logistic Regression</title><link href="https://zekry.github.io/blog/blog_2.html" rel="alternate"></link><published>2019-07-05T09:30:00-04:00</published><updated>2019-07-05T09:30:00-04:00</updated><author><name>Zekry</name></author><id>tag:zekry.github.io,2019-07-05:/blog/blog_2.html</id><summary type="html">&lt;p&gt;Logistic regression is a classification method built on the same concept as linear regression.  The advantage of logistic regression over other classification models is that logistic regression is a parametric linear model, which has a lot of explanatory power.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/logitmeme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;In classification problems, the response variable is categorical. The simplest case …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Logistic regression is a classification method built on the same concept as linear regression.  The advantage of logistic regression over other classification models is that logistic regression is a parametric linear model, which has a lot of explanatory power.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/logitmeme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;In classification problems, the response variable is categorical. The simplest case of classification is where the response variable is binary, meaning it can only take one of two values, such as true or false. Logistic regression takes a linear combination of explanatory variables plus an intercept term just like linear regression, but then it takes the result and passes it through the "logistic" function. The logistic function looks like an elongated S when plotted, opposed to the straight line in linear regression. Usually the middle point of that S curve, 50% probability, (unless decided otherwise) is the threshold were the cut off for belonging to either categories lies.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/logit_plot.png"&gt;&lt;/p&gt;
&lt;p&gt;The aim of logistic regression is to predict some unknown probability P for a successful event, for any given linear combination of independent variables (features).&lt;/p&gt;
&lt;p&gt;Logistic regression calculating log-odds or probability of a categorical response being "true" (1) is modeled as a linear combination of the features, however, using logit function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;B0&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;B1x1&lt;/span&gt;&lt;span class="p"&gt;....&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;BnXn&lt;/span&gt;        &lt;span class="k"&gt;or&lt;/span&gt;

  &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;B0&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;B1X1&lt;/span&gt;&lt;span class="p"&gt;....&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;BnXn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case the coefficients (B) are the size and direction of the relation between the predictor (X) and the log odds of outcome, which when exponentiated gives the odds which can be used to calculate probability given the value of predictor. Same outcome can be achieved by running predict_proba__, which yields an array of 2 numbers, probability of 0 and probability of 1. The one that is higher than the threshold determines the classification outcome.&lt;/p&gt;
&lt;p&gt;We can take the exponential of each of the coefficients to generate the odds ratios. This tells us how a 1 unit increase or decrease in a variable affects the odds of the outcome being 1 when other features are at fixed value.&lt;/p&gt;
&lt;p&gt;Also, a large positive coefficient implies that high values of the corresponding feature push the probability towards 1 and a large negative coefficient implies that high values of the corresponding feature push the probability towards 0.&lt;/p&gt;
&lt;p&gt;Equal odds are 1. 1 success for every 1 failure. 1:1
Equal probabilities are 0.5. 1 success for every 2 trials.
Odds can range from 0 to infinity. Odds greater than 1 indicates success is more likely than failure. Odds less than 1 indicates failure is more likely than success.
Probability can range from 0 to 1. Probability greater than 0.5 indicates success is more likely than failure. Probability less than 0.5 indicates failure is more likely than success.&lt;/p&gt;</content><category term="python"></category></entry><entry><title>Train-test-split</title><link href="https://zekry.github.io/blog/blog-1.html" rel="alternate"></link><published>2019-07-04T04:00:00-04:00</published><updated>2019-07-04T04:00:00-04:00</updated><author><name>Zekry</name></author><id>tag:zekry.github.io,2019-07-04:/blog/blog-1.html</id><summary type="html">&lt;p&gt;Train-test-split from scikit-learn provides an easy way to split your collected data into a training portion and a testing portion, which helps evaluate the chosen model before using it on new observations or to form predictions.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/train_test meme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;First we will have to import it from sklearn.model_selection&lt;/p&gt;
&lt;p&gt;from sklearn.model_selection import …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Train-test-split from scikit-learn provides an easy way to split your collected data into a training portion and a testing portion, which helps evaluate the chosen model before using it on new observations or to form predictions.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/train_test meme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;First we will have to import it from sklearn.model_selection&lt;/p&gt;
&lt;p&gt;from sklearn.model_selection import train_test_split&lt;/p&gt;
&lt;p&gt;We will need to specify our target column in (y) and the feature-columns/predictors we decided to use in our model (x). For example if we are working on a model to predict house prices then our target (y) could be sale-price and features/predictors might include columns that contain number of rooms, area in sqft, overall condition of the house, etc.&lt;/p&gt;
&lt;p&gt;Once the selection is done splitting the data is as easy as typing this line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are a few optional parameters that can be included as well to improve outcome:&lt;/p&gt;
&lt;p&gt;1- test_size :  float, int or None, optional (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It can be set to a float between 0.0 and 1.0 to indicate a proportion of the dataset that is to be considered for test.&lt;/li&gt;
&lt;li&gt;If set to an Int, that will be considered the number of samples to be included for testing.&lt;/li&gt;
&lt;li&gt;If left empty, it will be set to default value (0.25) or a value to compliment train_size, if specified.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2- train_size :  float, int, or None, (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It can be set to a float between 0.0 and 1.0 to indicate a proportion of the dataset that is to be considered for train.&lt;/li&gt;
&lt;li&gt;If set to an Int, that will be considered the number of samples to be included for training.&lt;/li&gt;
&lt;li&gt;If left empty, it will automatically compliment test_size.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3- random_state :  int, RandomState instance or None, optional (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If set to an Int, it will be the seed used by the random generator.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If set to RandomState instance or None, it will be the random generator without a seed (if running multiple times, outcome will not be the same)
4- shuffle : boolean, optional (default=True)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5- stratify : array-like or None (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This will split your data based on the proportion of values in the provided to the parameter. For example, if the variable provided is a column that is a     binary categorical variable with values 0 and 1 and there are 40% of zeros and 60% of ones, stratify will make sure that your random split has 40% of 0's and 60% of 1's.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further modifications applied to features or target columns should be applied to both train and test sets to avoid mismatch of datasets when fitting model or making predictions. For example, if a feature is dropped from the train set, it should also be dropped from the test set, or if using StandardScaler or LabelBinarizer, it has to be applied to the column in both sets.&lt;/p&gt;
&lt;p&gt;Next would be to train and test the model of choice.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/train on test.jpg"&gt;&lt;/p&gt;</content><category term="python"></category><category term="scikit-learn"></category></entry></feed>