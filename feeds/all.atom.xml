<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Blog</title><link href="https://zekry.github.io/blog/" rel="alternate"></link><link href="https://zekry.github.io/blog/feeds/all.atom.xml" rel="self"></link><id>https://zekry.github.io/blog/</id><updated>2019-08-01T09:40:00-04:00</updated><entry><title>Using APIs!</title><link href="https://zekry.github.io/blog/blog-3.html" rel="alternate"></link><published>2019-08-01T09:40:00-04:00</published><updated>2019-08-01T09:40:00-04:00</updated><author><name>Zekry</name></author><id>tag:zekry.github.io,2019-08-01:/blog/blog-3.html</id><summary type="html">&lt;p&gt;Using APIs&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/api.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;What is an API?
API stands for Application Programming Interface.It is a set of programming code/URLs that enables data transmission between one software product and another. It also contains the terms of this data exchange. We are going to cover an example of using an API …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Using APIs&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/api.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;What is an API?
API stands for Application Programming Interface.It is a set of programming code/URLs that enables data transmission between one software product and another. It also contains the terms of this data exchange. We are going to cover an example of using an API in python to get data and store it in a dataframe, as an example for collecting data for projects. APIs usually have a documentation page to explain how to interact with it.&lt;/p&gt;
&lt;p&gt;First, we are going to start with importing needed packages...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;JSON or JavaScript Object Notation is a minimal, readable format for structuring data. It is used primarily to transmit data between a server and web application. Most web APIs provide data in JSON for easy read.&lt;/p&gt;
&lt;p&gt;Now, We are going to use requests to query the API. We are going to use the OpenNotify API's ISS Pass endpoint that returns when the ISS will next pass over a given location on earth. But first will test it with a request for the current location of the ISS.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://api.open-notify.org/iss-now.json&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Response&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Response 200 is a good sign, this means our request worked. Next we are going to add the paramters for Toronto to get when the ISS is going to pass over. We can do this by adding an optional keyword argument, params, to our request. In this case, there are two parameters we need to pass:&lt;/p&gt;
&lt;p&gt;lat — The latitude of the location we want.
lon — The longitude of the location we want.&lt;/p&gt;
&lt;p&gt;We can do this by adding the query parameters to the url, like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;http://api.open-notify.org/iss-pass.json?lat=43.653225&amp;amp;lon=79.383186&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Response&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can also make a dictionary with these parameters, and then pass them into the requests.get function.&lt;/p&gt;
&lt;p&gt;It’s almost always preferable to setup the parameters as a dictionary, because requests takes care of some things that come up, like properly formatting the query parameters.&lt;/p&gt;
&lt;p&gt;We are going to do that and store our response for later use.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;43.653225&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lon&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;79.383186&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://api.open-notify.org/iss-pass.json&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{\n  &amp;quot;message&amp;quot;: &amp;quot;success&amp;quot;, \n  &amp;quot;request&amp;quot;: {\n    &amp;quot;altitude&amp;quot;: 100, \n    &amp;quot;datetime&amp;quot;: 1564663440, \n    &amp;quot;latitude&amp;quot;: 43.653225, \n    &amp;quot;longitude&amp;quot;: -79.383186, \n    &amp;quot;passes&amp;quot;: 5\n  }, \n  &amp;quot;response&amp;quot;: [\n    {\n      &amp;quot;duration&amp;quot;: 506, \n      &amp;quot;risetime&amp;quot;: 1564685872\n    }, \n    {\n      &amp;quot;duration&amp;quot;: 651, \n      &amp;quot;risetime&amp;quot;: 1564691567\n    }, \n    {\n      &amp;quot;duration&amp;quot;: 627, \n      &amp;quot;risetime&amp;quot;: 1564697394\n    }, \n    {\n      &amp;quot;duration&amp;quot;: 607, \n      &amp;quot;risetime&amp;quot;: 1564703249\n    }, \n    {\n      &amp;quot;duration&amp;quot;: 642, \n      &amp;quot;risetime&amp;quot;: 1564709068\n    }\n  ]\n}\n&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Server&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;nginx/1.10.3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Thu, 01 Aug 2019 13:30:47 GMT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Content-Type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;application/json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Content-Length&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;528&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Connection&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;keep-alive&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Via&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;1.1 vegur&amp;#39;&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As we can see the content is hard to read, this is where JSON helps. As we can see below the response is in a dictionary form with the full list of paramters and the data requested.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;message&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;success&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;request&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;altitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s1"&gt;&amp;#39;datetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564663440&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s1"&gt;&amp;#39;latitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;43&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;653225&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s1"&gt;&amp;#39;longitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;79&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;383186&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s1"&gt;&amp;#39;passes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="s1"&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;506&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564685872&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;651&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564691567&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;627&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564697394&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;607&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564703249&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;642&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564709068&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, we are going to take the part with the needed information and store it as a dataframe to a csv file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;506&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564685872&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;651&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564691567&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;627&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564697394&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;607&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564703249&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
 &lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;duration&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;642&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;risetime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1564709068&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;duration&lt;/th&gt;
      &lt;th&gt;risetime&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;506&lt;/td&gt;
      &lt;td&gt;1564685872&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;651&lt;/td&gt;
      &lt;td&gt;1564691567&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;627&lt;/td&gt;
      &lt;td&gt;1564697394&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;607&lt;/td&gt;
      &lt;td&gt;1564703249&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;642&lt;/td&gt;
      &lt;td&gt;1564709068&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;upcoming&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;response&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;upcoming&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ISS.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="python"></category><category term="API"></category></entry><entry><title>Interpreting Logistic Regression</title><link href="https://zekry.github.io/blog/blog_2.html" rel="alternate"></link><published>2019-07-05T09:30:00-04:00</published><updated>2019-07-05T09:30:00-04:00</updated><author><name>Zekry</name></author><id>tag:zekry.github.io,2019-07-05:/blog/blog_2.html</id><summary type="html">&lt;p&gt;Logistic regression is a classification method built on the same concept as linear regression.  The advantage of logistic regression over other classification models is that logistic regression is a parametric linear model, which has a lot of explanatory power.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/logitmeme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;In classification problems, the response variable is categorical. The simplest case …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Logistic regression is a classification method built on the same concept as linear regression.  The advantage of logistic regression over other classification models is that logistic regression is a parametric linear model, which has a lot of explanatory power.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/logitmeme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;In classification problems, the response variable is categorical. The simplest case of classification is where the response variable is binary, meaning it can only take one of two values, such as true or false. Logistic regression takes a linear combination of explanatory variables plus an intercept term just like linear regression, but then it takes the result and passes it through the "logistic" function. The logistic function looks like an elongated S when plotted, opposed to the straight line in linear regression. Usually the middle point of that S curve, 50% probability, (unless decided otherwise) is the threshold were the cut off for belonging to either categories lies.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/logit_plot.png"&gt;&lt;/p&gt;
&lt;p&gt;The aim of logistic regression is to predict some unknown probability P for a successful event, for any given linear combination of independent variables (features).&lt;/p&gt;
&lt;p&gt;Logistic regression calculating log-odds or probability of a categorical response being "true" (1) is modeled as a linear combination of the features, however, using logit function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;B0&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;B1x1&lt;/span&gt;&lt;span class="p"&gt;....&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;BnXn&lt;/span&gt;        &lt;span class="k"&gt;or&lt;/span&gt;

  &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;B0&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;B1X1&lt;/span&gt;&lt;span class="p"&gt;....&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;BnXn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case the coefficients (B) are the size and direction of the relation between the predictor (X) and the log odds of outcome, which when exponentiated gives the odds which can be used to calculate probability given the value of predictor. Same outcome can be achieved by running predict_proba__, which yields an array of 2 numbers, probability of 0 and probability of 1. The one that is higher than the threshold determines the classification outcome.&lt;/p&gt;
&lt;p&gt;We can take the exponential of each of the coefficients to generate the odds ratios. This tells us how a 1 unit increase or decrease in a variable affects the odds of the outcome being 1 when other features are at fixed value.&lt;/p&gt;
&lt;p&gt;Also, a large positive coefficient implies that high values of the corresponding feature push the probability towards 1 and a large negative coefficient implies that high values of the corresponding feature push the probability towards 0.&lt;/p&gt;
&lt;p&gt;Equal odds are 1. 1 success for every 1 failure. 1:1
Equal probabilities are 0.5. 1 success for every 2 trials.
Odds can range from 0 to infinity. Odds greater than 1 indicates success is more likely than failure. Odds less than 1 indicates failure is more likely than success.
Probability can range from 0 to 1. Probability greater than 0.5 indicates success is more likely than failure. Probability less than 0.5 indicates failure is more likely than success.&lt;/p&gt;</content><category term="python"></category></entry><entry><title>Train-test-split</title><link href="https://zekry.github.io/blog/blog-1.html" rel="alternate"></link><published>2019-07-04T04:00:00-04:00</published><updated>2019-07-04T04:00:00-04:00</updated><author><name>Zekry</name></author><id>tag:zekry.github.io,2019-07-04:/blog/blog-1.html</id><summary type="html">&lt;p&gt;Train-test-split from scikit-learn provides an easy way to split your collected data into a training portion and a testing portion, which helps evaluate the chosen model before using it on new observations or to form predictions.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/train_test meme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;First we will have to import it from sklearn.model_selection&lt;/p&gt;
&lt;p&gt;from sklearn.model_selection import …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Train-test-split from scikit-learn provides an easy way to split your collected data into a training portion and a testing portion, which helps evaluate the chosen model before using it on new observations or to form predictions.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/train_test meme.jpg"&gt;&lt;/p&gt;
&lt;p&gt;First we will have to import it from sklearn.model_selection&lt;/p&gt;
&lt;p&gt;from sklearn.model_selection import train_test_split&lt;/p&gt;
&lt;p&gt;We will need to specify our target column in (y) and the feature-columns/predictors we decided to use in our model (x). For example if we are working on a model to predict house prices then our target (y) could be sale-price and features/predictors might include columns that contain number of rooms, area in sqft, overall condition of the house, etc.&lt;/p&gt;
&lt;p&gt;Once the selection is done splitting the data is as easy as typing this line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are a few optional parameters that can be included as well to improve outcome:&lt;/p&gt;
&lt;p&gt;1- test_size :  float, int or None, optional (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It can be set to a float between 0.0 and 1.0 to indicate a proportion of the dataset that is to be considered for test.&lt;/li&gt;
&lt;li&gt;If set to an Int, that will be considered the number of samples to be included for testing.&lt;/li&gt;
&lt;li&gt;If left empty, it will be set to default value (0.25) or a value to compliment train_size, if specified.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2- train_size :  float, int, or None, (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It can be set to a float between 0.0 and 1.0 to indicate a proportion of the dataset that is to be considered for train.&lt;/li&gt;
&lt;li&gt;If set to an Int, that will be considered the number of samples to be included for training.&lt;/li&gt;
&lt;li&gt;If left empty, it will automatically compliment test_size.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3- random_state :  int, RandomState instance or None, optional (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If set to an Int, it will be the seed used by the random generator.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If set to RandomState instance or None, it will be the random generator without a seed (if running multiple times, outcome will not be the same)
4- shuffle : boolean, optional (default=True)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5- stratify : array-like or None (default=None)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This will split your data based on the proportion of values in the provided to the parameter. For example, if the variable provided is a column that is a     binary categorical variable with values 0 and 1 and there are 40% of zeros and 60% of ones, stratify will make sure that your random split has 40% of 0's and 60% of 1's.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further modifications applied to features or target columns should be applied to both train and test sets to avoid mismatch of datasets when fitting model or making predictions. For example, if a feature is dropped from the train set, it should also be dropped from the test set, or if using StandardScaler or LabelBinarizer, it has to be applied to the column in both sets.&lt;/p&gt;
&lt;p&gt;Next would be to train and test the model of choice.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/train on test.jpg"&gt;&lt;/p&gt;</content><category term="python"></category><category term="scikit-learn"></category></entry></feed>